{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“ HOMEWORK 3 â€” GitHub Actions CI Pipeline for Data Quality\n",
    "\n",
    "This notebook demonstrates how to create a **CI/CD pipeline** that automatically validates data quality on every commit using GitHub Actions.\n",
    "\n",
    "## ğŸ¯ Learning Objectives\n",
    "- Set up a GitHub repository with data quality checks\n",
    "- Create GitHub Actions workflow files\n",
    "- Integrate Great Expectations / Pydantic validation in CI\n",
    "- Handle validation failures with proper exit codes\n",
    "- (Optional) Slack notifications on CI failure\n",
    "\n",
    "## ğŸ“ Repository Structure\n",
    "\n",
    "```\n",
    "your-repo/\n",
    "â”œâ”€â”€ .github/\n",
    "â”‚   â””â”€â”€ workflows/\n",
    "â”‚       â””â”€â”€ data_quality.yml      # GitHub Actions workflow\n",
    "â”œâ”€â”€ data/\n",
    "â”‚   â””â”€â”€ amazon_sales.csv          # Dataset\n",
    "â”œâ”€â”€ src/\n",
    "â”‚   â””â”€â”€ validate_data.py          # Validation script\n",
    "â”œâ”€â”€ requirements.txt              # Python dependencies\n",
    "â””â”€â”€ README.md\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1ï¸âƒ£ Prerequisites\n",
    "\n",
    "Before starting:\n",
    "- GitHub account\n",
    "- Git installed locally\n",
    "- Basic understanding of Git commands\n",
    "- (Optional) Slack webhook URL for notifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2ï¸âƒ£ Create Repository Files\n",
    "\n",
    "Let's create all the files needed for our CI pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 requirements.txt\n",
    "\n",
    "Python dependencies for the validation script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements_txt = \"\"\"\n",
    "great_expectations>=1.0.0\n",
    "pydantic>=2.0.0\n",
    "pandas>=2.0.0\n",
    "requests>=2.28.0\n",
    "\"\"\".strip()\n",
    "\n",
    "# Save to file\n",
    "with open('requirements.txt', 'w') as f:\n",
    "    f.write(requirements_txt)\n",
    "\n",
    "print(\"âœ… requirements.txt created\")\n",
    "print(requirements_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Validation Script (validate_data.py)\n",
    "\n",
    "This script will be executed by GitHub Actions. It must:\n",
    "- Load and validate the data\n",
    "- Print a summary\n",
    "- **Exit with code 1 if validation fails** (critical for CI!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_script = '''\n",
    "\"\"\"\n",
    "Data Quality Validation Script for CI/CD Pipeline\n",
    "=================================================\n",
    "\n",
    "This script validates the Amazon Sales dataset using Great Expectations.\n",
    "It exits with code 1 if validation fails, causing the CI pipeline to fail.\n",
    "\n",
    "Usage:\n",
    "    python src/validate_data.py\n",
    "\n",
    "Exit Codes:\n",
    "    0 - All validations passed\n",
    "    1 - One or more validations failed\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import great_expectations as gx\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "DATA_PATH = \"data/amazon_sales.csv\"\n",
    "\n",
    "# Slack webhook from environment variable (set in GitHub Secrets)\n",
    "SLACK_WEBHOOK_URL = os.environ.get(\"SLACK_WEBHOOK_URL\", \"\")\n",
    "\n",
    "# Expected values\n",
    "VALID_STATUSES = [\n",
    "    \"Cancelled\", \"Shipped\", \"Shipped - Delivered to Buyer\", \"Pending\",\n",
    "    \"Shipped - Returned to Seller\", \"Shipped - Rejected by Buyer\",\n",
    "    \"Shipped - Returning to Seller\", \"Shipped - Out for Delivery\",\n",
    "    \"Shipped - Picked Up\"\n",
    "]\n",
    "VALID_FULFILMENT = [\"Merchant\", \"Amazon\"]\n",
    "VALID_CURRENCIES = [\"INR\"]\n",
    "VALID_COUNTRIES = [\"IN\"]\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# VALIDATION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def load_data(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load CSV data into DataFrame.\"\"\"\n",
    "    print(f\"\\nğŸ“‚ Loading data from: {path}\")\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        print(f\"âŒ ERROR: File not found: {path}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    print(f\"   Rows: {len(df)}, Columns: {len(df.columns)}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def run_validation(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"Run Great Expectations validation on the DataFrame.\"\"\"\n",
    "    print(\"\\nğŸ” Running Great Expectations Validation...\")\n",
    "    \n",
    "    # Create ephemeral context\n",
    "    context = gx.get_context()\n",
    "    \n",
    "    # Set up data source\n",
    "    data_source = context.data_sources.add_pandas(name=\"pandas_source\")\n",
    "    data_asset = data_source.add_dataframe_asset(name=\"amazon_sales\")\n",
    "    batch_definition = data_asset.add_batch_definition_whole_dataframe(\"full_data\")\n",
    "    \n",
    "    # Create expectation suite\n",
    "    suite = gx.ExpectationSuite(name=\"amazon_sales_suite\")\n",
    "    \n",
    "    # Add expectations\n",
    "    suite.add_expectation(\n",
    "        gx.expectations.ExpectColumnValuesToNotBeNull(column=\"Order ID\")\n",
    "    )\n",
    "    suite.add_expectation(\n",
    "        gx.expectations.ExpectColumnValuesToBeUnique(column=\"Order ID\")\n",
    "    )\n",
    "    suite.add_expectation(\n",
    "        gx.expectations.ExpectColumnValuesToBeBetween(column=\"Qty\", min_value=0)\n",
    "    )\n",
    "    suite.add_expectation(\n",
    "        gx.expectations.ExpectColumnValuesToBeBetween(column=\"Amount\", min_value=0)\n",
    "    )\n",
    "    suite.add_expectation(\n",
    "        gx.expectations.ExpectColumnValuesToBeInSet(column=\"Status\", value_set=VALID_STATUSES)\n",
    "    )\n",
    "    suite.add_expectation(\n",
    "        gx.expectations.ExpectColumnValuesToBeInSet(column=\"Fulfilment\", value_set=VALID_FULFILMENT)\n",
    "    )\n",
    "    suite.add_expectation(\n",
    "        gx.expectations.ExpectColumnValuesToBeInSet(column=\"currency\", value_set=VALID_CURRENCIES)\n",
    "    )\n",
    "    suite.add_expectation(\n",
    "        gx.expectations.ExpectColumnValuesToBeInSet(column=\"ship-country\", value_set=VALID_COUNTRIES)\n",
    "    )\n",
    "    suite.add_expectation(\n",
    "        gx.expectations.ExpectColumnValuesToMatchRegex(column=\"Date\", regex=r\"^\\\\d{2}-\\\\d{2}-\\\\d{2}$\")\n",
    "    )\n",
    "    \n",
    "    # Add suite to context\n",
    "    suite = context.suites.add(suite)\n",
    "    \n",
    "    # Create validation definition\n",
    "    validation_definition = gx.ValidationDefinition(\n",
    "        name=\"amazon_sales_validation\",\n",
    "        data=batch_definition,\n",
    "        suite=suite\n",
    "    )\n",
    "    validation_definition = context.validation_definitions.add(validation_definition)\n",
    "    \n",
    "    # Run validation\n",
    "    results = validation_definition.run(batch_parameters={\"dataframe\": df})\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def process_results(results) -> dict:\n",
    "    \"\"\"Process validation results and return summary.\"\"\"\n",
    "    results_dict = results.to_json_dict()\n",
    "    expectation_results = results_dict.get(\"results\", [])\n",
    "    \n",
    "    passed = []\n",
    "    failed = []\n",
    "    \n",
    "    for exp_result in expectation_results:\n",
    "        exp_config = exp_result.get(\"expectation_config\", {})\n",
    "        exp_type = exp_config.get(\"type\", \"Unknown\")\n",
    "        column = exp_config.get(\"kwargs\", {}).get(\"column\", \"N/A\")\n",
    "        success = exp_result.get(\"success\", False)\n",
    "        \n",
    "        info = {\n",
    "            \"expectation\": exp_type,\n",
    "            \"column\": column,\n",
    "            \"result\": exp_result.get(\"result\", {})\n",
    "        }\n",
    "        \n",
    "        if success:\n",
    "            passed.append(info)\n",
    "        else:\n",
    "            failed.append(info)\n",
    "    \n",
    "    return {\n",
    "        \"success\": results_dict.get(\"success\", False),\n",
    "        \"total\": len(expectation_results),\n",
    "        \"passed\": passed,\n",
    "        \"failed\": failed\n",
    "    }\n",
    "\n",
    "\n",
    "def print_summary(summary: dict):\n",
    "    \"\"\"Print validation summary to console.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"   DATA QUALITY VALIDATION SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    status = \"âœ… PASSED\" if summary[\"success\"] else \"âŒ FAILED\"\n",
    "    print(f\"\\n   Overall Status: {status}\")\n",
    "    print(f\"   Total Expectations: {summary['total']}\")\n",
    "    print(f\"   Passed: {len(summary['passed'])}\")\n",
    "    print(f\"   Failed: {len(summary['failed'])}\")\n",
    "    \n",
    "    if summary[\"failed\"]:\n",
    "        print(\"\\n\" + \"-\" * 60)\n",
    "        print(\"   FAILED EXPECTATIONS:\")\n",
    "        print(\"-\" * 60)\n",
    "        for f in summary[\"failed\"]:\n",
    "            print(f\"   âŒ {f['expectation']} (Column: {f['column']})\")\n",
    "            result = f.get('result', {})\n",
    "            if result.get('unexpected_count'):\n",
    "                print(f\"      Unexpected count: {result['unexpected_count']}\")\n",
    "            if result.get('partial_unexpected_list'):\n",
    "                print(f\"      Sample values: {result['partial_unexpected_list'][:3]}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "\n",
    "def send_slack_notification(summary: dict) -> bool:\n",
    "    \"\"\"Send Slack notification if webhook URL is configured.\"\"\"\n",
    "    if not SLACK_WEBHOOK_URL:\n",
    "        print(\"\\nâš ï¸  Slack notification skipped (SLACK_WEBHOOK_URL not set)\")\n",
    "        return False\n",
    "    \n",
    "    print(\"\\nğŸ“¤ Sending Slack notification...\")\n",
    "    \n",
    "    emoji = \"âœ…\" if summary[\"success\"] else \"âŒ\"\n",
    "    color = \"#36a64f\" if summary[\"success\"] else \"#dc3545\"\n",
    "    status_text = \"PASSED\" if summary[\"success\"] else \"FAILED\"\n",
    "    \n",
    "    # Get GitHub context if available\n",
    "    repo = os.environ.get(\"GITHUB_REPOSITORY\", \"local\")\n",
    "    run_id = os.environ.get(\"GITHUB_RUN_ID\", \"N/A\")\n",
    "    actor = os.environ.get(\"GITHUB_ACTOR\", \"local\")\n",
    "    \n",
    "    failed_text = \"\"\n",
    "    if summary[\"failed\"]:\n",
    "        failed_text = \"\\\\n\".join([\n",
    "            f\"â€¢ `{f['expectation']}` ({f['column']})\"\n",
    "            for f in summary[\"failed\"]\n",
    "        ])\n",
    "    \n",
    "    message = {\n",
    "        \"attachments\": [{\n",
    "            \"color\": color,\n",
    "            \"blocks\": [\n",
    "                {\n",
    "                    \"type\": \"header\",\n",
    "                    \"text\": {\n",
    "                        \"type\": \"plain_text\",\n",
    "                        \"text\": f\"{emoji} CI Data Quality: {status_text}\",\n",
    "                        \"emoji\": True\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"section\",\n",
    "                    \"fields\": [\n",
    "                        {\"type\": \"mrkdwn\", \"text\": f\"*Repository:*\\\\n{repo}\"},\n",
    "                        {\"type\": \"mrkdwn\", \"text\": f\"*Triggered by:*\\\\n{actor}\"},\n",
    "                        {\"type\": \"mrkdwn\", \"text\": f\"*Passed:*\\\\n{len(summary['passed'])} âœ“\"},\n",
    "                        {\"type\": \"mrkdwn\", \"text\": f\"*Failed:*\\\\n{len(summary['failed'])} âœ—\"}\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }]\n",
    "    }\n",
    "    \n",
    "    if failed_text:\n",
    "        message[\"attachments\"][0][\"blocks\"].append({\n",
    "            \"type\": \"section\",\n",
    "            \"text\": {\"type\": \"mrkdwn\", \"text\": f\"*Failed Checks:*\\\\n{failed_text}\"}\n",
    "        })\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            SLACK_WEBHOOK_URL,\n",
    "            data=json.dumps(message),\n",
    "            headers={\"Content-Type\": \"application/json\"}\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            print(\"   âœ… Slack notification sent!\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"   âŒ Slack failed: {response.status_code}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Slack error: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main entry point for CI pipeline.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"   ğŸš€ DATA QUALITY CI PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"   Timestamp: {datetime.now().isoformat()}\")\n",
    "    \n",
    "    # Load data\n",
    "    df = load_data(DATA_PATH)\n",
    "    \n",
    "    # Run validation\n",
    "    results = run_validation(df)\n",
    "    \n",
    "    # Process results\n",
    "    summary = process_results(results)\n",
    "    \n",
    "    # Print summary\n",
    "    print_summary(summary)\n",
    "    \n",
    "    # Send Slack notification\n",
    "    send_slack_notification(summary)\n",
    "    \n",
    "    # Exit with appropriate code\n",
    "    if not summary[\"success\"]:\n",
    "        print(\"\\nğŸ’¥ Validation FAILED - Exiting with code 1\")\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        print(\"\\nğŸ‰ Validation PASSED - Exiting with code 0\")\n",
    "        sys.exit(0)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''.strip()\n",
    "\n",
    "# Create src directory and save script\n",
    "import os\n",
    "os.makedirs('src', exist_ok=True)\n",
    "\n",
    "with open('src/validate_data.py', 'w') as f:\n",
    "    f.write(validation_script)\n",
    "\n",
    "print(\"âœ… src/validate_data.py created\")\n",
    "print(f\"   Lines: {len(validation_script.splitlines())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 GitHub Actions Workflow (data_quality.yml)\n",
    "\n",
    "This is the heart of the CI pipeline. It defines:\n",
    "- **Triggers**: When to run (push, pull_request, manual)\n",
    "- **Environment**: Python version, dependencies\n",
    "- **Steps**: What to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_yaml = '''\n",
    "# ============================================================================\n",
    "# Data Quality Validation Workflow\n",
    "# ============================================================================\n",
    "# This workflow runs data quality checks on every push and pull request.\n",
    "# It will fail the build if any validation fails.\n",
    "#\n",
    "# Features:\n",
    "#   - Runs on push to main/master\n",
    "#   - Runs on pull requests\n",
    "#   - Can be triggered manually\n",
    "#   - Sends Slack notifications (optional)\n",
    "# ============================================================================\n",
    "\n",
    "name: Data Quality Validation\n",
    "\n",
    "# ============================================================================\n",
    "# TRIGGERS\n",
    "# ============================================================================\n",
    "on:\n",
    "  # Run on push to main branches\n",
    "  push:\n",
    "    branches:\n",
    "      - main\n",
    "      - master\n",
    "    paths:\n",
    "      - 'data/**'           # Only run when data files change\n",
    "      - 'src/**'            # Or when validation scripts change\n",
    "      - '.github/workflows/**'\n",
    "  \n",
    "  # Run on pull requests\n",
    "  pull_request:\n",
    "    branches:\n",
    "      - main\n",
    "      - master\n",
    "  \n",
    "  # Allow manual trigger from GitHub UI\n",
    "  workflow_dispatch:\n",
    "\n",
    "# ============================================================================\n",
    "# JOBS\n",
    "# ============================================================================\n",
    "jobs:\n",
    "  validate:\n",
    "    name: Validate Data Quality\n",
    "    runs-on: ubuntu-latest\n",
    "    \n",
    "    steps:\n",
    "      # ------------------------------------------\n",
    "      # Step 1: Checkout repository\n",
    "      # ------------------------------------------\n",
    "      - name: ğŸ“¥ Checkout code\n",
    "        uses: actions/checkout@v4\n",
    "      \n",
    "      # ------------------------------------------\n",
    "      # Step 2: Set up Python\n",
    "      # ------------------------------------------\n",
    "      - name: ğŸ Set up Python\n",
    "        uses: actions/setup-python@v5\n",
    "        with:\n",
    "          python-version: '3.11'\n",
    "          cache: 'pip'  # Cache pip dependencies\n",
    "      \n",
    "      # ------------------------------------------\n",
    "      # Step 3: Install dependencies\n",
    "      # ------------------------------------------\n",
    "      - name: ğŸ“¦ Install dependencies\n",
    "        run: |\n",
    "          python -m pip install --upgrade pip\n",
    "          pip install -r requirements.txt\n",
    "      \n",
    "      # ------------------------------------------\n",
    "      # Step 4: Run validation\n",
    "      # ------------------------------------------\n",
    "      - name: ğŸ” Run Data Quality Validation\n",
    "        env:\n",
    "          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}\n",
    "        run: |\n",
    "          python src/validate_data.py\n",
    "      \n",
    "      # ------------------------------------------\n",
    "      # Step 5: Upload validation report (optional)\n",
    "      # ------------------------------------------\n",
    "      - name: ğŸ“Š Upload validation results\n",
    "        if: always()  # Run even if validation fails\n",
    "        uses: actions/upload-artifact@v4\n",
    "        with:\n",
    "          name: validation-results\n",
    "          path: |\n",
    "            valid_rows.csv\n",
    "            invalid_rows.csv\n",
    "          retention-days: 7\n",
    "          if-no-files-found: ignore\n",
    "'''.strip()\n",
    "\n",
    "# Create .github/workflows directory and save workflow\n",
    "os.makedirs('.github/workflows', exist_ok=True)\n",
    "\n",
    "with open('.github/workflows/data_quality.yml', 'w') as f:\n",
    "    f.write(workflow_yaml)\n",
    "\n",
    "print(\"âœ… .github/workflows/data_quality.yml created\")\n",
    "print(f\"   Lines: {len(workflow_yaml.splitlines())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Sample Data\n",
    "\n",
    "Copy the dataset to the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Sample dataset with intentional errors\n",
    "sample_data = \"\"\"index,Order ID,Date,Status,Fulfilment,Sales Channel ,ship-service-level,Style,SKU,Category,Size,ASIN,Courier Status,Qty,currency,Amount,ship-city,ship-state,ship-postal-code,ship-country,promotion-ids,B2B,fulfilled-by,Unnamed: 22\n",
    "0,405-8078784-5731545,04-30-22,Cancelled,Merchant,Amazon.in,Standard,SET389,SET389-KR-NP-S,Set,S,B09KXVBD7Z,,0,INR,647.62,MUMBAI,MAHARASHTRA,400081.0,IN,,False,Easy Ship,\n",
    "1,171-9198151-1101146,04-30-22,Shipped - Delivered to Buyer,Merchant,Amazon.in,Standard,JNE3781,JNE3781-KR-XXXL,kurta,3XL,B09K3WFS32,Shipped,1,INR,406.0,BENGALURU,KARNATAKA,560085.0,IN,\"Amazon PLCC Free-Financing\",False,Easy Ship,\n",
    "2,404-0687676-7273146,04-30-22,Shipped,Amazon,Amazon.in,Expedited,JNE3371,JNE3371-KR-XL,kurta,XL,B07WV4JV4D,Shipped,1,INR,329.0,NAVI MUMBAI,MAHARASHTRA,410210.0,IN,IN Core Free Shipping,True,,\n",
    "3,403-9615377-8133951,04-30-22,Cancelled,Merchant,Amazon.in,Standard,J0341,J0341-DR-L,Western Dress,L,B099NRCT7B,,0,INR,753.33,PUDUCHERRY,PUDUCHERRY,605008.0,IN,,False,Easy Ship,\n",
    "4,407-1069790-7240320,04-30-22,Shipped,Amazon,Amazon.in,Expedited,JNE3671,JNE3671-TU-XXXL,Top,3XL,B098714BZP,Shipped,1,INR,574.0,CHENNAI,TAMIL NADU,600073.0,IN,,False,,\n",
    "5,404-1490984-4578765,04-30-22,Shipped,Amazon,Amazon.in,Expedited,SET264,SET264-KR-NP-XL,Set,XL,B08YN7XDSG,Shipped,1,INR,824.0,GHAZIABAD,UTTAR PRADESH,201102.0,IN,IN Core Free Shipping,False,,\n",
    "6,408-5748499-6859555,04-30-22,Shipped,Amazon,Amazon.in,Expedited,J0095,J0095-SET-L,Set,L,B08CMHNWBN,Shipped,1,INR,653.0,CHANDIGARH,CHANDIGARH,160036.0,IN,IN Core Free Shipping,False,,\n",
    "7,406-7807733-3785945,04-30-22,Shipped - Delivered to Buyer,Merchant,Amazon.in,Standard,JNE3405,JNE3405-KR-S,kurta,S,B081WX4G4Q,Shipped,1,INR,399.0,HYDERABAD,TELANGANA,500032.0,IN,\"Amazon PLCC Free-Financing\",False,Easy Ship,\n",
    "8,407-5443024-5233168,04-30-22,Cancelled,Amazon,Amazon.in,Expedited,SET200,SET200-KR-NP-A-XXXL,Set,3XL,B08L91ZZXN,Cancelled,0,INR,,HYDERABAD,TELANGANA,500008.0,IN,IN Core Free Shipping,False,,\n",
    "9,402-4393761-0311520,04-30-22,Shipped,Amazon,Amazon.in,Expedited,JNE3461,JNE3461-KR-XXL,kurta,XXL,B08B3XF5MH,Shipped,1,INR,363.0,Chennai,TAMIL NADU,600041.0,IN,,False,,\n",
    "10,407-5633625-6970741,04-30-22,Shipped,Amazon,Amazon.in,Expedited,JNE3160,JNE3160-KR-G-S,kurta,S,B07K3YQLF1,Shipped,1,INR,685.0,CHENNAI,TAMIL NADU,600073.0,IN,,False,,\n",
    "11,,04-30-22,Pending,Merchant,Amazon.in,Standard,JNE1234,JNE1234-KR-M,kurta,M,B07K3YQLF2,Pending,2,INR,450.0,DELHI,DELHI,110001.0,IN,,False,Easy Ship,\n",
    "12,408-1234567-8901234,04-30-22,Shipped,Amazon,Amazon.in,Expedited,SET100,SET100-KR-L,Set,L,B08L91ZZXN,Shipped,-1,INR,550.0,MUMBAI,MAHARASHTRA,400001.0,IN,,False,,\n",
    "13,409-9876543-2109876,05-01-22,Shipped,Amazon,Amazon.in,Expedited,JNE5000,JNE5000-KR-XL,kurta,XL,B07WV4JV4E,Shipped,1,USD,299.0,PUNE,MAHARASHTRA,411001.0,US,,False,,\n",
    "14,410-1111111-2222222,invalid-date,Shipped,Amazon,Amazon.in,Standard,TOP200,TOP200-TU-M,Top,M,B098714BZQ,Shipped,1,INR,399.0,JAIPUR,RAJASTHAN,302001.0,IN,,False,,\n",
    "\"\"\"\n",
    "\n",
    "with open('data/amazon_sales.csv', 'w') as f:\n",
    "    f.write(sample_data)\n",
    "\n",
    "print(\"âœ… data/amazon_sales.csv created\")\n",
    "print(f\"   Rows: 15 (including 6 intentional errors)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_content = '''\n",
    "# Data Quality CI Pipeline\n",
    "\n",
    "![Data Quality](https://github.com/YOUR_USERNAME/YOUR_REPO/actions/workflows/data_quality.yml/badge.svg)\n",
    "\n",
    "This repository demonstrates automated data quality validation using GitHub Actions.\n",
    "\n",
    "## ğŸš€ Features\n",
    "\n",
    "- **Automated Validation**: Runs on every push and pull request\n",
    "- **Great Expectations**: Industry-standard data validation framework\n",
    "- **Slack Notifications**: Get alerted when validation fails\n",
    "- **CI/CD Integration**: Fails the build if data quality issues are detected\n",
    "\n",
    "## ğŸ“ Structure\n",
    "\n",
    "```\n",
    "â”œâ”€â”€ .github/workflows/\n",
    "â”‚   â””â”€â”€ data_quality.yml    # GitHub Actions workflow\n",
    "â”œâ”€â”€ data/\n",
    "â”‚   â””â”€â”€ amazon_sales.csv    # Sample dataset\n",
    "â”œâ”€â”€ src/\n",
    "â”‚   â””â”€â”€ validate_data.py    # Validation script\n",
    "â”œâ”€â”€ requirements.txt        # Python dependencies\n",
    "â””â”€â”€ README.md\n",
    "```\n",
    "\n",
    "## ğŸ”§ Setup\n",
    "\n",
    "1. Fork this repository\n",
    "2. (Optional) Add Slack webhook to repository secrets:\n",
    "   - Go to Settings â†’ Secrets and variables â†’ Actions\n",
    "   - Add `SLACK_WEBHOOK_URL`\n",
    "\n",
    "## ğŸ§ª Validation Rules\n",
    "\n",
    "| Column | Rule | Description |\n",
    "|--------|------|-------------|\n",
    "| Order ID | Not Null | Every order must have an ID |\n",
    "| Order ID | Unique | No duplicate order IDs |\n",
    "| Qty | >= 0 | Quantity cannot be negative |\n",
    "| Amount | >= 0 | Amount cannot be negative |\n",
    "| Status | In Set | Must be valid status value |\n",
    "| currency | = INR | Must be INR |\n",
    "| ship-country | = IN | Must be IN |\n",
    "| Date | Format | Must match MM-DD-YY |\n",
    "\n",
    "## ğŸƒ Local Testing\n",
    "\n",
    "```bash\n",
    "# Install dependencies\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Run validation\n",
    "python src/validate_data.py\n",
    "```\n",
    "\n",
    "## ğŸ“ License\n",
    "\n",
    "MIT License\n",
    "'''.strip()\n",
    "\n",
    "with open('README.md', 'w') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(\"âœ… README.md created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3ï¸âƒ£ View Created Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all created files\n",
    "import os\n",
    "\n",
    "print(\"ğŸ“ Repository Structure:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for root, dirs, files in os.walk('.'):\n",
    "    # Skip hidden directories except .github\n",
    "    dirs[:] = [d for d in dirs if not d.startswith('.') or d == '.github']\n",
    "    \n",
    "    level = root.replace('.', '').count(os.sep)\n",
    "    indent = '  ' * level\n",
    "    print(f'{indent}{os.path.basename(root)}/')\n",
    "    \n",
    "    subindent = '  ' * (level + 1)\n",
    "    for file in files:\n",
    "        if not file.startswith('.'):\n",
    "            print(f'{subindent}{file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4ï¸âƒ£ Test Validation Locally\n",
    "\n",
    "Before pushing to GitHub, test the validation script locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the validation script (simulating what CI will do)\n",
    "# Note: In a real scenario, you would run this from command line\n",
    "\n",
    "print(\"ğŸ§ª Testing validation script locally...\\n\")\n",
    "print(\"Run this command in your terminal:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"python src/validate_data.py\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5ï¸âƒ£ Push to GitHub\n",
    "\n",
    "Now push everything to GitHub to trigger the CI pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Git commands to push to GitHub\n",
    "git_commands = \"\"\"\n",
    "# ============================================\n",
    "# Git Commands to Push to GitHub\n",
    "# ============================================\n",
    "\n",
    "# 1. Initialize git repository (if not already)\n",
    "git init\n",
    "\n",
    "# 2. Add all files\n",
    "git add .\n",
    "\n",
    "# 3. Commit\n",
    "git commit -m \"Add data quality CI pipeline\"\n",
    "\n",
    "# 4. Create GitHub repository and add remote\n",
    "# (Create repo on GitHub first, then:)\n",
    "git remote add origin https://github.com/YOUR_USERNAME/YOUR_REPO.git\n",
    "\n",
    "# 5. Push to GitHub\n",
    "git branch -M main\n",
    "git push -u origin main\n",
    "\n",
    "# ============================================\n",
    "# The CI pipeline will automatically run!\n",
    "# Check: https://github.com/YOUR_USERNAME/YOUR_REPO/actions\n",
    "# ============================================\n",
    "\"\"\"\n",
    "\n",
    "print(git_commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6ï¸âƒ£ Configure Slack Notifications (Optional)\n",
    "\n",
    "To receive Slack notifications when validation fails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slack_setup_instructions = \"\"\"\n",
    "# ============================================\n",
    "# Setting Up Slack Notifications\n",
    "# ============================================\n",
    "\n",
    "1. Create Slack Webhook:\n",
    "   - Go to https://api.slack.com/apps\n",
    "   - Create New App â†’ From scratch\n",
    "   - Add \"Incoming Webhooks\" feature\n",
    "   - Create webhook for your channel\n",
    "   - Copy the webhook URL\n",
    "\n",
    "2. Add to GitHub Secrets:\n",
    "   - Go to your repository on GitHub\n",
    "   - Settings â†’ Secrets and variables â†’ Actions\n",
    "   - Click \"New repository secret\"\n",
    "   - Name: SLACK_WEBHOOK_URL\n",
    "   - Value: (paste your webhook URL)\n",
    "   - Click \"Add secret\"\n",
    "\n",
    "3. That's it! \n",
    "   The CI pipeline will now send Slack notifications\n",
    "   whenever validation runs.\n",
    "\n",
    "# ============================================\n",
    "\"\"\"\n",
    "\n",
    "print(slack_setup_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7ï¸âƒ£ Understanding the CI Workflow\n",
    "\n",
    "Let's break down what happens when you push code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_explanation = \"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    CI/CD PIPELINE FLOW                      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ git push â”‚\n",
    "    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚\n",
    "         â–¼\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ GitHub detects push  â”‚\n",
    "    â”‚ to main branch       â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "               â”‚\n",
    "               â–¼\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ Workflow triggered   â”‚\n",
    "    â”‚ (data_quality.yml)   â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "               â”‚\n",
    "               â–¼\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ 1. Checkout code     â”‚\n",
    "    â”‚ 2. Setup Python 3.11 â”‚\n",
    "    â”‚ 3. Install deps      â”‚\n",
    "    â”‚ 4. Run validation    â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "               â”‚\n",
    "         â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”\n",
    "         â”‚           â”‚\n",
    "         â–¼           â–¼\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ Exit 0  â”‚ â”‚ Exit 1  â”‚\n",
    "    â”‚ SUCCESS â”‚ â”‚ FAILURE â”‚\n",
    "    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜\n",
    "         â”‚           â”‚\n",
    "         â–¼           â–¼\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ âœ… Pass â”‚ â”‚ âŒ Fail     â”‚\n",
    "    â”‚ Green   â”‚ â”‚ Red         â”‚\n",
    "    â”‚ badge   â”‚ â”‚ Block merge â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                      â”‚\n",
    "                      â–¼\n",
    "               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "               â”‚ ğŸ“± Slack    â”‚\n",
    "               â”‚ notificationâ”‚\n",
    "               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\"\"\"\n",
    "\n",
    "print(workflow_explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8ï¸âƒ£ Branch Protection (Best Practice)\n",
    "\n",
    "To prevent merging code that fails validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_protection = \"\"\"\n",
    "# ============================================\n",
    "# Setting Up Branch Protection Rules\n",
    "# ============================================\n",
    "\n",
    "1. Go to your repository on GitHub\n",
    "\n",
    "2. Settings â†’ Branches\n",
    "\n",
    "3. Click \"Add branch protection rule\"\n",
    "\n",
    "4. Configure:\n",
    "   - Branch name pattern: main\n",
    "   - âœ… Require a pull request before merging\n",
    "   - âœ… Require status checks to pass before merging\n",
    "   - âœ… Require branches to be up to date before merging\n",
    "   - Select status check: \"Validate Data Quality\"\n",
    "\n",
    "5. Click \"Create\"\n",
    "\n",
    "Now:\n",
    "- Direct pushes to main are blocked\n",
    "- PRs must pass data quality checks\n",
    "- Bad data can't be merged! ğŸ›¡ï¸\n",
    "\n",
    "# ============================================\n",
    "\"\"\"\n",
    "\n",
    "print(branch_protection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“š Summary\n",
    "\n",
    "In this homework, we learned:\n",
    "\n",
    "1. **GitHub Actions Basics**: Workflows, triggers, jobs, steps\n",
    "2. **CI/CD for Data**: Automated validation on every commit\n",
    "3. **Exit Codes**: How to signal success/failure to CI\n",
    "4. **Secrets Management**: Storing Slack webhook securely\n",
    "5. **Branch Protection**: Preventing bad data from being merged\n",
    "\n",
    "### ğŸ‹ï¸ Bonus Exercises\n",
    "\n",
    "1. Add a **scheduled run** (e.g., every day at 8 AM)\n",
    "2. Create a **Pydantic validation** workflow\n",
    "3. Add **data profiling** step that uploads a report\n",
    "4. Implement **multi-environment** validation (dev, staging, prod)\n",
    "\n",
    "### ğŸ”— Resources\n",
    "\n",
    "- [GitHub Actions Documentation](https://docs.github.com/en/actions)\n",
    "- [GitHub Actions Workflow Syntax](https://docs.github.com/en/actions/reference/workflow-syntax-for-github-actions)\n",
    "- [Great Expectations + GitHub Actions](https://docs.greatexpectations.io/docs/deployment_patterns/how_to_use_great_expectations_with_github_actions/)\n",
    "- [Slack Incoming Webhooks](https://api.slack.com/messaging/webhooks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
